{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import car_racing_simulator.VehicleModel as VehicleModel\n",
    "import car_racing_simulator.Track as Track\n",
    "import math\n",
    "from car_racing.network import Actor as Actor\n",
    "from car_racing.orca_env_function import getNFcollosionreward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Actor(10, 2, std=0.1)\n",
    "p2 = Actor(10, 2, std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compete(player1, player2):\n",
    "    p1.load_state_dict(torch.load(\"../car_racing/pretrained_models/\" + player1 + \".pth\"))\n",
    "    p2.load_state_dict(torch.load(\"../car_racing/pretrained_models/\" + player2 + \".pth\"))\n",
    "\n",
    "    config = json.load(open('../car_racing/config.json'))\n",
    "    track1 = Track.Track(config)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    vehicle_model = VehicleModel.VehicleModel(config[\"n_batch\"], device, config)\n",
    "\n",
    "    mat_action1 = []\n",
    "    mat_action2 = []\n",
    "\n",
    "    mat_state1 = []\n",
    "    mat_reward1 = []\n",
    "    mat_done = []\n",
    "\n",
    "    mat_state2 = []\n",
    "    global_coordinates1 = []\n",
    "    curvilinear_coordinates1 = []\n",
    "\n",
    "    global_coordinates2 = []\n",
    "    curvilinear_coordinates2 = []\n",
    "    init_size  = 10000\n",
    "    curr_batch_size = init_size\n",
    "    state_c1 = torch.zeros(curr_batch_size, config[\"n_state\"])  # state[:, 6:12].view(6)\n",
    "    state_c2 = torch.zeros(curr_batch_size, config[\"n_state\"])  # state[:, 6:12].view(6)\n",
    "    state_c1[:, 0] = torch.zeros((curr_batch_size))#torch.rand((curr_batch_size))\n",
    "    state_c2[:, 0] = torch.zeros((curr_batch_size))#torch.FloatTensor([2.0])#torch.rand((curr_batch_size))\n",
    "\n",
    "    a = torch.rand(curr_batch_size)\n",
    "    a_linear = (a>0.5)*torch.ones(curr_batch_size)\n",
    "    state_c1[:, 1] = a_linear*0.2 - 0.1\n",
    "    state_c2[:, 1] = -state_c1[:, 1]\n",
    "    # state_c1[:, 1] = -0.1#torch.zeros((curr_batch_size))#torch.rand((curr_batch_size))\n",
    "    # state_c2[:, 1] = 0.1#torch.zeros((curr_batch_size))#torch.FloatTensor([2.0])#torch.rand((curr_batch_size))\n",
    "    done_c1 = torch.zeros((curr_batch_size)) <= -0.1\n",
    "    done_c2 = torch.zeros((curr_batch_size)) <= -0.1\n",
    "    prev_coll_c1 = torch.zeros((curr_batch_size)) <= -0.1\n",
    "    prev_coll_c2 = torch.zeros((curr_batch_size)) <= -0.1\n",
    "    counter1 = torch.zeros((curr_batch_size))\n",
    "    counter2 = torch.zeros((curr_batch_size))\n",
    "    over_mat = []\n",
    "    overtakings = torch.zeros((curr_batch_size))\n",
    "    prev_leading_player = torch.cat([torch.zeros(int(curr_batch_size/2)) <= 0.1,torch.zeros(int(curr_batch_size/2)) <= -0.1])\n",
    "    c1_out=0\n",
    "    c2_out=0\n",
    "    t=0\n",
    "    a_win=0\n",
    "    b_win=0\n",
    "    overtakings_p1 = 0\n",
    "    overtakings_p2 = 0\n",
    "    for i in range(2000):\n",
    "\n",
    "        dist1 = p1(torch.cat([state_c1[:, 0:5], state_c2[:, 0:5]], dim=1))\n",
    "        action1 = dist1.sample()\n",
    "\n",
    "\n",
    "        dist2 = p2(torch.cat([state_c2[:, 0:5], state_c1[:, 0:5]], dim=1))\n",
    "        action2 = dist2.sample()\n",
    "\n",
    "        mat_state1.append(state_c1[0:5])\n",
    "        mat_action1.append(action1.detach())\n",
    "\n",
    "        prev_state_c1 = state_c1\n",
    "        prev_state_c2 = state_c2\n",
    "\n",
    "        state_c1 = vehicle_model.dynModelBlendBatch(state_c1.view(-1, 6), action1.view(-1, 2)).view(-1, 6)\n",
    "        state_c2 = vehicle_model.dynModelBlendBatch(state_c2.view(-1, 6), action2.view(-1, 2)).view(-1, 6)\n",
    "\n",
    "        state_c1 = (state_c1.transpose(0, 1) * (~done_c1) + prev_state_c1.transpose(0, 1) * (done_c1)).transpose(0, 1)\n",
    "        state_c2 = (state_c2.transpose(0, 1) * (~done_c2) + prev_state_c2.transpose(0, 1) * (done_c2)).transpose(0, 1)\n",
    "\n",
    "        reward1, reward2, done_c1, done_c2,state_c1, state_c2, n_c1, n_c2  = getNFcollosionreward(state_c1, state_c2,\n",
    "                                                                          vehicle_model.getLocalBounds(state_c1[:, 0]),\n",
    "                                                                          vehicle_model.getLocalBounds(state_c2[:, 0]),\n",
    "                                                                          prev_state_c1, prev_state_c2)\n",
    "\n",
    "        done = ((done_c1) * (done_c2))\n",
    "        remaining_xo = ~done\n",
    "        # prev_coll_c1 = coll_c1[remaining_xo]  # removing elements that died\n",
    "        # prev_coll_c2 = coll_c2[remaining_xo]\n",
    "        counter1 = counter1[remaining_xo]\n",
    "        counter2 = counter2[remaining_xo]\n",
    "        # check for collision\n",
    "        c1_out = c1_out + n_c1\n",
    "        c2_out = c2_out + n_c2\n",
    "\n",
    "        #check for overtake state_c1[:,2]\n",
    "        leading_player = torch.ones(state_c1.size(0))*((state_c1[:,0]-state_c2[:,0])>0)# True means 1 is leading false means other is leading\n",
    "        overtakings = overtakings + torch.ones(leading_player.size(0))*(leading_player!=prev_leading_player)\n",
    "        if torch.sum(torch.ones(leading_player.size(0))*(leading_player!=prev_leading_player))>0:\n",
    "            temp=1\n",
    "        overtakings_p1_bool= (leading_player!=prev_leading_player)*(leading_player==(torch.zeros((leading_player.size(0)))<=0.1))\n",
    "        overtakings_p1 = overtakings_p1  + torch.sum(torch.ones(leading_player.size(0))*overtakings_p1_bool)\n",
    "        overtakings_p2_bool= (leading_player!=prev_leading_player)*(leading_player==(torch.zeros((leading_player.size(0)))<=-0.1))\n",
    "        overtakings_p2 = overtakings_p2  + torch.sum(torch.ones(leading_player.size(0))*overtakings_p2_bool)\n",
    "        prev_leading_player = leading_player[remaining_xo]\n",
    "        out_state_c1 = state_c1[~remaining_xo]\n",
    "        out_state_c2 = state_c2[~remaining_xo]\n",
    "        state_c1 = state_c1[remaining_xo]\n",
    "        state_c2 = state_c2[remaining_xo]\n",
    "        curr_batch_size = state_c1.size(0)\n",
    "\n",
    "        if curr_batch_size < remaining_xo.size(0):\n",
    "            t=t+1\n",
    "            # if t==1:\n",
    "            #     print(i)\n",
    "            a_win = a_win + torch.sum(torch.ones(out_state_c1.size(0))*(out_state_c1[:,0]>out_state_c2[:,0]))\n",
    "            b_win = b_win + torch.sum(torch.ones(out_state_c1.size(0))*(out_state_c1[:,0]<out_state_c2[:,0]))\n",
    "            over_mat.append(torch.sum(overtakings[~remaining_xo]))\n",
    "            element_deducted = ~(done_c1 * done_c2)\n",
    "            done_c1 = done_c1[element_deducted]\n",
    "            done_c2 = done_c2[element_deducted]\n",
    "            overtakings = overtakings[remaining_xo]\n",
    "            # print(over_mat)\n",
    "\n",
    "        if np.all(done.numpy()) == True or i==1999:\n",
    "        # if ((done_c1) * (done_c2)):\n",
    "        #     print(torch.sum(torch.stack(over_mat)), c1_out,c2_out, a_win,b_win, overtakings_p1,overtakings_p2)\n",
    "            print('Normalized score for races between ' + player1 + ' vs ' + player2,)\n",
    "            print('Overtakes per lap', np.array(torch.sum(torch.stack(over_mat))/init_size))\n",
    "            print( player1 + ' Won:', np.array(a_win / init_size))\n",
    "            print( player2 + ' Won:', np.array(b_win / init_size))\n",
    "            print( player1 + ' Collisions:', np.array(c1_out/init_size))\n",
    "            print( player2 + ' Collisions:', np.array(c2_out/init_size))\n",
    "            print( player1 + ' Overtake:', np.array(overtakings_p1/init_size))\n",
    "            print( player2 + ' Overtake:', np.array(overtakings_p2/init_size))\n",
    "\n",
    "            # print(\"done\", i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function Compete, \n",
    "Play 10,000 matches between player 1 and player 2. <br /> \n",
    "Based on matches, it prints normalized wins along with normalized collisions and overtakes in a lap. <br /> \n",
    "Below we play matches between CoPG vs GDA, TRCoPO vs TRGDA and CoPG vs TRCoPO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized score for races between CoPG vs GDA\n",
      "Overtakes per lap 2.0606\n",
      "CoPG Won: 1.0\n",
      "GDA Won: 0.0\n",
      "CoPG Collisions: 0.1806\n",
      "GDA Collisions: 16.1392\n",
      "CoPG Overtake: 1.2803\n",
      "GDA Overtake: 0.7803\n"
     ]
    }
   ],
   "source": [
    "Compete('CoPG','GDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized score for races between TRCoPO vs TRGDA\n",
      "Overtakes per lap 2.0752\n",
      "TRCoPO Won: 0.9998\n",
      "TRGDA Won: 1e-04\n",
      "TRCoPO Collisions: 0.2522\n",
      "TRGDA Collisions: 1.8809\n",
      "TRCoPO Overtake: 1.2876\n",
      "TRGDA Overtake: 0.7877\n"
     ]
    }
   ],
   "source": [
    "Compete('TRCoPO','TRGDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized score for races between CoPG vs TRCoPO\n",
      "Overtakes per lap 3.8346\n",
      "CoPG Won: 0.2332\n",
      "TRCoPO Won: 0.7668\n",
      "CoPG Collisions: 0.3043\n",
      "TRCoPO Collisions: 0.3232\n",
      "CoPG Overtake: 1.7839\n",
      "TRCoPO Overtake: 2.0507\n"
     ]
    }
   ],
   "source": [
    "Compete('CoPG','TRCoPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
